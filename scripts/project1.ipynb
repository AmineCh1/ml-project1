{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from helpers import *\n",
    "import seaborn as sns\n",
    "import math\n",
    "from proj1_helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_TRAIN_PATH = '../data/train.csv'  \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test) # ????\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index0, y0, x_test0 = partition_data(tX, y, 0)\n",
    "index1, y1, x_test1 = partition_data(tX, y, 1)\n",
    "index2, y2, x_test2 = partition_data(tX, y, 2)\n",
    "index3, y3, x_test3 = partition_data(tX, y, 3)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standardize the 4 batches of data, and a bias component/ feature to each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_test0 = np.hstack((np.ones((x_test0.shape[0],1)),standardize_data(x_test0)))\n",
    "std_test1 = np.hstack((np.ones((x_test1.shape[0],1)),standardize_data(x_test1)))\n",
    "std_test2 = np.hstack((np.ones((x_test2.shape[0],1)),standardize_data(x_test2)))\n",
    "std_test3 = np.hstack((np.ones((x_test3.shape[0],1)),standardize_data(x_test3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(feature_combination(std_test0,np.sin,[0,1]))|\n",
    "print(std_test0[:,-1])\n",
    "print(expand_features(std_test0,3).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_features(std_test0,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to find any correlations between features of the standardized data, by taking a look at their correlation matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_mat_0 = compute_corr(std_test0[:,1:-1])\n",
    "corr_mat_1 = compute_corr(std_test1)[:,1:] \n",
    "corr_mat_2 = compute_corr(std_test2)[:,1:] \n",
    "corr_mat_3 = compute_corr(std_test3)[:,1:] \n",
    "    \n",
    "corrs = [corr_mat_0,corr_mat_1,corr_mat_2,corr_mat_3]\n",
    "\n",
    "# for elem in corrs:\n",
    "#     visualize_corr(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that among the 4 batches of partitioned data, the first batch has a feature which is strictly correlated to the other ! \n",
    "Furthermore, for the second, thrid , and fourth batch, we observe that some features here and there have very high correlation coefficients, greater than 0.95 ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try to find the  combination of lambda and polynomial expansion degree that results in the most accurate model with respect to cross validation, using ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    poly = np.ones((len(x), 1))\n",
    "    for deg in range(1, degree+1):\n",
    "        poly = np.c_[poly, np.power(x, deg)]\n",
    "    return poly[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = expand_features(std_test0,2)\n",
    "# x_o = build_poly(std_test0,2)\n",
    "# print(std_test0[0:2])\n",
    "# print(\"----------------\")\n",
    "# print(\"Antoine's Version\")\n",
    "# print(x_o[0:2,0:60])\n",
    "# print(\"----------------\")\n",
    "# print(\"Mine\")\n",
    "# print(X[0:2,])\n",
    "# forward_selection(y0,std_test0)\n",
    "# cross_validation(11, y0, expand_features(std_test0,12),model='ridge_reg',lambda_=0.5,logging=True)\n",
    "a = expand_features(std_test0,12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees= np.arange(1,20)\n",
    "for d in degrees: \n",
    "        print(d)\n",
    "        b = expand_features(std_test0,d)\n",
    "        a = cross_validation(11, y0, b, model='lq',logging=True)\n",
    "        acc.append(a)\n",
    "                      \n",
    "print(\"Best parameters: lambda={}, polynomial degree ={}. Acuracy:{}\".format(ind[np.argmax(acc)][0],ind[np.argmax(acc)][1],np.max(acc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
