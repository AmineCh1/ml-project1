{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_TRAIN_PATH = '../data/train.csv'  \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index0, y0, x_train0 = partition_data(tX, y, 0)\n",
    "index1, y1, x_train1 = partition_data(tX, y, 1)\n",
    "index2, y2, x_train2 = partition_data(tX, y, 2)\n",
    "index3, y3, x_train3 = partition_data(tX, y, 3)\n",
    "\n",
    "index0_t, y0_t, x_test0 = partition_data(tX_test, y_test, 0)\n",
    "index1_t, y1_t, x_test1 = partition_data(tX_test, y_test, 1)\n",
    "index2_t, y2_t, x_test2 = partition_data(tX_test, y_test, 2)\n",
    "index3_t, y3_t, x_test3 = partition_data(tX_test, y_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standardize the 4 batches of data, and add a bias component/ feature to each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_train0, mean_x0, std_x0 = standardize_data(x_train0)\n",
    "std_train1, mean_x1, std_x1 = standardize_data(x_train1)\n",
    "std_train2, mean_x2, std_x2 = standardize_data(x_train2)\n",
    "std_train3, mean_x3, std_x3 = standardize_data(x_train3)\n",
    "\n",
    "std_train0 = np.hstack((np.ones((x_train0.shape[0],1)),std_train0))\n",
    "std_train1 = np.hstack((np.ones((x_train1.shape[0],1)),std_train1))\n",
    "std_train2 = np.hstack((np.ones((x_train2.shape[0],1)),std_train2))\n",
    "std_train3 = np.hstack((np.ones((x_train3.shape[0],1)),std_train3))\n",
    "\n",
    "std_test0 = np.hstack((np.ones((x_test0.shape[0],1)),(x_test0-mean_x0)/std_x0))\n",
    "std_test1 = np.hstack((np.ones((x_test1.shape[0],1)),(x_test1-mean_x1)/std_x1))\n",
    "std_test2 = np.hstack((np.ones((x_test2.shape[0],1)),(x_test2-mean_x2)/std_x2))\n",
    "std_test3 = np.hstack((np.ones((x_test3.shape[0],1)),(x_test3-mean_x3)/std_x3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to find any correlations between features of the standardized data, by taking a look at their correlation matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_mat_0 = compute_corr(std_train0[:,1:-1])\n",
    "corr_mat_1 = compute_corr(std_train1)[:,1:] \n",
    "corr_mat_2 = compute_corr(std_train2)[:,1:] \n",
    "corr_mat_3 = compute_corr(std_train3)[:,1:] \n",
    "    \n",
    "corrs = [corr_mat_0,corr_mat_1,corr_mat_2,corr_mat_3]\n",
    "\n",
    "for elem in corrs:\n",
    "    visualize_corr(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that among the 4 batches of partitioned data, the first batch has a feature which is strictly correlated to the other ! \n",
    "Furthermore, for the second, third , and fourth batch, we observe that some features here and there have very high correlation coefficients, greater than 0.95 ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try to find the  combination of lambda and polynomial expansion degree that results in the most accurate model with respect to cross validation, using ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_params(y, tx, K, max_degree=13):\n",
    "    degrees= np.arange(1, max_degree+1)\n",
    "    lambdas = np.logspace(-4, -2, 10)\n",
    "    lambdas = np.append(lambdas, 0)\n",
    "    acc = []\n",
    "    ind = []\n",
    "    for d in degrees: \n",
    "        for l in lambdas:\n",
    "            ind.append((d, l))\n",
    "            b = build_poly(tx, d)\n",
    "            a = cross_validation(K, y, b, model='ridge_reg',logging=True, lambda_= l, seed=0)\n",
    "            acc.append(a)\n",
    "    best_d_l, acc = ind[np.argmax(acc)],np.max(acc)\n",
    "    print(\"Best parameters: for  polynomial degree ={}, lambda={} Acuracy:{}\".format(best_d_l[0], best_d_l[1], acc))\n",
    "    return best_d_l, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_params(y0,std_train0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_params(y1,std_train1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_params(y2,std_train2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_params(y3,std_train3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3001edce25f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuild_poly_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd_train0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg_log_reg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001668\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mw_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuild_poly_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd_train1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg_log_reg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0007742\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mw_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuild_poly_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg_log_reg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0012915\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mw_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuild_poly_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd_train3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg_log_reg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0007742\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_model' is not defined"
     ]
    }
   ],
   "source": [
    "w_0 = run_model(y0,build_poly_2(std_train0,12),model='ridge_reg', lambda_=0.0001668)\n",
    "w_1 = run_model(y1,build_poly_2(std_train1,12),model='ridge_reg', lambda_=0.0007742)\n",
    "w_2 = run_model(y2,build_poly_2(std_train2,12),model='ridge_reg', lambda_=0.0012915)\n",
    "w_3 = run_model(y3,build_poly_2(std_train3,13),model='ridge_reg', lambda_=0.0007742)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0 =predict_labels(w_0,build_poly(std_test0,12))\n",
    "label_1 =predict_labels(w_1,build_poly(std_test1,12))\n",
    "label_2 =predict_labels(w_2,build_poly(std_test2,12))\n",
    "label_3 =predict_labels(w_3,build_poly(std_test3,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.empty(len(y_test))\n",
    "labels[index0_t] = label_0\n",
    "labels[index1_t] = label_1\n",
    "labels[index2_t] = label_2\n",
    "labels[index3_t] = label_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename submission file name\n",
    "# OUTPUT_PATH = '../data/submission-ridge.csv' # TODO: fill in desired name of output file for submission\n",
    "create_csv_submission(ids_test, labels, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
